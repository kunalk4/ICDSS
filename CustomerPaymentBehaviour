# -*- coding: utf-8 -*-
"""
Spyder Editor

This is a file for the Customer Behaviour Prediction challenge.
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import tensorflow as tf

# replace DaysLate as 0 when early, or 1 when late
def binClassifierLate(df):    
    days_late = []
    
    for index, row in df.iterrows():
        if row['DaysLate'] == 0:
            days_late.append(1)
        else:
            days_late.append(0)
            
    df['DaysLateBin'] = days_late
    return(df)
    
# Define the normalized function
def min_max_normalized(data):
    col_max = np.max(data, axis=0)
    col_min = np.min(data, axis=0)
    
    return np.divide(data - col_min, col_max - col_min)
    
def main():
    
    # read in payment dataset and get info
    # change for particular filepath
    filename = r"H:\Customer Behaviour\Dataset.csv"
    df1 = pd.read_csv(filename)
    
    # basic info
    print(df1.shape)
    print(df1.head())
    print(df1.info())
    
    df1 = binClassifierLate(df1)
    
    # grouping 0s and 1s in DaysLate with InvoiceAmount and DaysToSettle
    grouped = df1.groupby(df1['DaysLateBin'])
    print (grouped)
    
    # for loop to split groupby object 
    list1 = []
    for name, group in grouped:
        print(name)
        print(group)
        list1.append(name)
    
    # splitting to form two dfs based on 0 or 1 value    
    df2 = grouped.get_group(list1[0])
    df2 = df2.reset_index()
    print(len(df2))
    
    df3 = grouped.get_group(list1[1])
    df3 = df3.reset_index()
    print(len(df3))
    
    dfs = pd.concat([df2,df3])
    dfs = dfs.reset_index()
    print(dfs)
    
    # speed = f(InvoiceAmount, DaysToSettle)
    
    # creating plots for Invoice Amount vs Days to settle for late (0)
    # and early (1) customers
    
    plt.scatter(dfs[:877].InvoiceAmount, dfs[:877].DaysToSettle, label = 'Late')
    plt.scatter(dfs[877:].InvoiceAmount, dfs[877:].DaysToSettle, label = 'On time')
    plt.xlabel('InvoiceAmount')
    plt.ylabel('DaysToSettle')
    plt.legend(loc='best')
    
    print (df1.info())
    # conclusion is that when days to settle increases over 30 days
    # the the payment will be late
    # this can be seen as the graph has split population
    # on either side after 30 days
    
    # create dataframes for tensorflow analysis
    x1 = df1[['InvoiceAmount', 'DaysToSettle']].copy()
    x = x1.values
    y = df1.DaysLateBin.values
    # tensor flow part
    
    # set seed for numpy and tensorflow
    # set for reproducible results
    
    seed = 5
    np.random.seed(seed)
    tf.set_random_seed(seed)
    
    # training data 70% 
    # testing data 30%
    
    # set replace=False, Avoid double sampling
    train_index = np.random.choice(len(x), round(len(x) * 0.8), replace=False)
   
    # different set
    test_index = np.array(list(set(range(len(x))) - set(train_index)))
    train_x = x[train_index]
    train_y = y[train_index]
    test_x = x[test_index]
    test_y = y[test_index]
    
    # defined normalised function
    
    # Normalized processing, must be placed after the data set segmentation, 
    # otherwise the test set will be affected by the training set
    
    train_x = min_max_normalized(train_x)
    test_x = min_max_normalized(test_x)

    # Begin building the model framework
    # Declare the variables that need to be learned and initialization
    # There are 4 features here, A's dimension is (2, 1)
    A = tf.Variable(tf.random_normal(shape=[2, 1]))
    b = tf.Variable(tf.random_normal(shape=[1, 1]))
    init = tf.global_variables_initializer()
    sess = tf.Session()
    sess.run(init)
    
       # Define placeholders
    data = tf.placeholder(dtype=tf.float32, shape=[None, 2])
    target = tf.placeholder(dtype=tf.float32, shape=[None, 1])
    
    # Declare the model you need to learn
    mod = tf.matmul(data, A) + b

    # Declare loss function
    # Use the sigmoid cross-entropy loss function,
    # first doing a sigmoid on the model result and then using 
    # the cross-entropy loss function
    loss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits
                          (logits=mod, labels=target))
    
    # Define the learning rateï¼Œ batch_size etc.
    learning_rate = 0.003
    batch_size = 30
    iter_num = 1500
    
    # Define the optimizer
    opt = tf.train.GradientDescentOptimizer(learning_rate)
    
    # Define the goal
    goal = opt.minimize(loss)
    
    # Define the accuracy
    # The default threshold is 0.5, rounded off directly
    prediction = tf.round(tf.sigmoid(mod))
    # Bool into float32 type
    correct = tf.cast(tf.equal(prediction, target), dtype=tf.float32)
    # Average
    accuracy = tf.reduce_mean(correct)
    # End of the definition of the model framework
    
    # Start training model
    # Define the variable that stores the result
    loss_trace = []
    train_acc = []
    test_acc = []
    
    # training model
    
    for epoch in range(iter_num):
        # Generate random batch index
        batch_index = np.random.choice(len(train_x), size=batch_size)
        batch_train_x = train_x[batch_index]
        batch_train_y = np.matrix(train_y[batch_index]).T
        sess.run(goal, feed_dict={data: batch_train_x, target: batch_train_y})
        temp_loss = sess.run(loss, feed_dict={data: batch_train_x, target: batch_train_y})
        # convert into a matrix, and the shape of the placeholder to correspond
        temp_train_acc = sess.run(accuracy, feed_dict={data: train_x, target: np.matrix(train_y).T})
        temp_test_acc = sess.run(accuracy, feed_dict={data: test_x, target: np.matrix(test_y).T})
        # recode the result
        loss_trace.append(temp_loss)
        train_acc.append(temp_train_acc)
        test_acc.append(temp_test_acc)
        # output
        if (epoch + 1) % 300 == 0:
            print('epoch: {:4d} loss: {:5f} train_acc: {:5f} test_acc: {:5f}'.
                  format(epoch + 1, temp_loss, temp_train_acc, temp_test_acc))

    # Visualization of the results
    # loss function
    plt.plot(loss_trace)
    plt.title('Cross Entropy Loss')
    plt.xlabel('epoch')
    plt.ylabel('loss')
    plt.show()
    
    # accuracy
    plt.plot(train_acc, 'b-', label='train accuracy')
    plt.plot(test_acc, 'k-', label='test accuracy')
    plt.xlabel('epoch')
    plt.ylabel('accuracy')
    plt.title('Train and Test Accuracy')
    plt.legend(loc='best')
    plt.show()
    
if __name__ == '__main__':
    main()
    
    


    
